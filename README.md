# Vision Transformer (ViT) Implementation in PyTorch

This repository contains a clean and concise PyTorch implementation of the Vision Transformer (ViT) as described in the paper "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale".

The implementation includes the core components of the ViT architecture: patch embedding, positional embeddings, the transformer encoder (multi-head attention and feed-forward layers), and the classification head.

# References
- An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale: https://arxiv.org/abs/2010.11929
- Inspired by various open-source ViT implementations, particularly those using einops.